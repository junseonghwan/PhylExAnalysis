{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.23.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run ExtractPhyloWGSResults.py and Rscripts/ProcessBSCITEResults.R first.\n",
    "\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "from sklearn.metrics.cluster import adjusted_mutual_info_score\n",
    "from sklearn.metrics.cluster import v_measure_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/Users/seonghwanjun/data/cell-line/bulk/OV2295/genotype/\"\n",
    "\n",
    "gt = pd.read_csv(\"/Users/seonghwanjun/data/cell-line/bulk/OV2295/genotype/gt.txt\", header=0, sep=\" \")\n",
    "valid_clone_names = [\"A_B_C_D_E_F_G_H_I\", \"A_B_C_D\", \"A_B\", \"C_D\", \"A\", \"B\", \"C\", \"D\", \"E_F_G_H_I\", \"E_F\", \"E\", \"F\"]\n",
    "\n",
    "# Evaluate the ancestral metric.\n",
    "# Get the true ancestral metric: not many SNVs, just do a plain double for loops. \n",
    "snv_count = gt.shape[0]\n",
    "A = np.zeros(shape = (snv_count, snv_count))\n",
    "for i in range(snv_count):\n",
    "    clone_i = set(gt.iloc[i][\"CloneName\"].split(\"_\"))\n",
    "    for j in range(snv_count):\n",
    "        clone_j = set(gt.iloc[j][\"CloneName\"].split(\"_\"))\n",
    "        if clone_i != clone_j and clone_j.issubset(clone_i):\n",
    "            A[i,j] = 1\n",
    "\n",
    "idx = np.array(np.where(gt[\"CloneName\"].isin(valid_clone_names)))[0]\n",
    "valid_idx = np.ix_(idx, idx)\n",
    "A0 = A[valid_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.87046922 0.87925848 0.8427254  0.03993384]\n",
      "[0.03885913 0.06316747 0.0461935  0.02158111]\n",
      "[[0.87329505 0.88976462 0.84461452 0.03638941]\n",
      " [0.89512617 0.90580255 0.87393241 0.03213611]\n",
      " [0.74920556 0.62172987 0.69092814 0.13090737]\n",
      " [0.90218254 0.90779706 0.8782858  0.03213611]\n",
      " [0.89512617 0.90580255 0.87393241 0.03213611]\n",
      " [0.89512617 0.90580255 0.87393241 0.03213611]\n",
      " [0.8683263  0.88960707 0.83554984 0.036862  ]\n",
      " [0.88968235 0.90566878 0.86488983 0.0326087 ]\n",
      " [0.88968235 0.90566878 0.86488983 0.0326087 ]\n",
      " [0.88968235 0.90566878 0.86488983 0.0326087 ]\n",
      " [0.77857314 0.81919142 0.74447363 0.04914934]\n",
      " [0.89512617 0.90580255 0.87393241 0.03213611]\n",
      " [0.86540286 0.8889076  0.84151696 0.02835539]\n",
      " [0.88968235 0.90566878 0.86488983 0.0326087 ]\n",
      " [0.87329505 0.88976462 0.84461452 0.03638941]\n",
      " [0.88968235 0.90566878 0.86488983 0.0326087 ]\n",
      " [0.87329505 0.88976462 0.84461452 0.03638941]\n",
      " [0.83391511 0.84165523 0.80022687 0.05151229]\n",
      " [0.88968235 0.90566878 0.86488983 0.0326087 ]\n",
      " [0.87329505 0.88976462 0.84461452 0.03638941]]\n"
     ]
    }
   ],
   "source": [
    "# Our method.\n",
    "rep_count = 20\n",
    "metrics = np.zeros([rep_count, 4])\n",
    "for rep in range(rep_count):\n",
    "    #rep_path = \"/Users/seonghwanjun/data/cell-line/bulk/OV2295/genotype/results/rep\" + str(rep)\n",
    "    rep_path = \"/Users/seonghwanjun/PhylExAnalysis/_output/HGSOC/phylex/chain\" + str(rep)\n",
    "    predicted = pd.read_csv(rep_path + \"/joint/tree0/cluster_labels.tsv\", header=None, sep=\"\\t\", names=[\"ID\", \"CloneName\"])\n",
    "    tbl_join = predicted.join(gt, lsuffix='_caller', rsuffix='_other')\n",
    "    ret = tbl_join[tbl_join[\"CloneName_other\"].isnull() == False]\n",
    "    ret_valid = tbl_join[tbl_join[\"CloneName_other\"].isin(valid_clone_names)]\n",
    "\n",
    "    ancestral_matrix = pd.read_csv(rep_path + \"/joint/tree0/ancestral_matrix.csv\", header=None)\n",
    "    ancestral_matrix = np.asarray(ancestral_matrix)\n",
    "    ancestral_matrix_0 = ancestral_matrix[valid_idx]\n",
    "    metrics[rep,0] = v_measure_score(ret_valid[\"CloneName_other\"], ret_valid[\"CloneName_caller\"])\n",
    "    metrics[rep,1] = adjusted_rand_score(ret_valid[\"CloneName_other\"], ret_valid[\"CloneName_caller\"])\n",
    "    metrics[rep,2] = adjusted_mutual_info_score(ret_valid[\"CloneName_other\"], ret_valid[\"CloneName_caller\"])\n",
    "    metrics[rep,3] = np.mean(np.abs(ancestral_matrix_0 - A0))\n",
    "    \n",
    "# V-measure, adjusted rand score, adjusted mutual info, ancestral metric.\n",
    "print(metrics.mean(0))\n",
    "print(metrics.std(0))\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.23721991 0.28376081 0.17966876 0.20370983]\n",
      "[0.06754353 0.0773308  0.07521317 0.03178864]\n"
     ]
    }
   ],
   "source": [
    "# TSSB.\n",
    "metrics = np.zeros([rep_count, 4])\n",
    "for rep in range(rep_count):\n",
    "    rep_path = \"/Users/seonghwanjun/data/cell-line/bulk/OV2295/genotype/bulk_only/rep\" + str(rep)\n",
    "    predicted = pd.read_csv(rep_path + \"/joint/tree0/cluster_labels.tsv\", header=None, sep=\"\\t\", names=[\"ID\", \"CloneName\"])\n",
    "    tbl_join = predicted.join(gt, lsuffix='_caller', rsuffix='_other')\n",
    "    ret = tbl_join[tbl_join[\"CloneName_other\"].isnull() == False]\n",
    "    ret_valid = tbl_join[tbl_join[\"CloneName_other\"].isin(valid_clone_names)]\n",
    "\n",
    "    ancestral_matrix = pd.read_csv(rep_path + \"/joint/tree0/ancestral_matrix.csv\", header=None)\n",
    "    ancestral_matrix = np.asarray(ancestral_matrix)\n",
    "    ancestral_matrix_0 = ancestral_matrix[valid_idx]\n",
    "    metrics[rep,0] = v_measure_score(ret_valid[\"CloneName_other\"], ret_valid[\"CloneName_caller\"])\n",
    "    metrics[rep,1] = adjusted_rand_score(ret_valid[\"CloneName_other\"], ret_valid[\"CloneName_caller\"])\n",
    "    metrics[rep,2] = adjusted_mutual_info_score(ret_valid[\"CloneName_other\"], ret_valid[\"CloneName_caller\"])\n",
    "    metrics[rep,3] = np.mean(np.abs(ancestral_matrix_0 - A0))\n",
    "    \n",
    "# V-measure, adjusted rand score, adjusted mutual info, ancestral metric.\n",
    "print(metrics.mean(0))\n",
    "print(metrics.std(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4829870174461928\n",
      "0.04580008626266983\n",
      "0.0744216195098232\n"
     ]
    }
   ],
   "source": [
    "# ddClone\n",
    "pred_path = os.path.join(data_path, \"ddClone\")\n",
    "predicted = pd.read_table(os.path.join(pred_path, \"results.txt\"), sep=\" \")\n",
    "predicted.columns=[\"ID\", \"phi\", \"CloneName\"]\n",
    "\n",
    "tbl_join = predicted.join(gt, lsuffix='_caller', rsuffix='_other')\n",
    "ret = tbl_join[tbl_join[\"CloneName_other\"].isnull() == False]\n",
    "ret_valid = tbl_join[tbl_join[\"CloneName_other\"].isin(valid_clone_names)]\n",
    "\n",
    "print(v_measure_score(ret_valid[\"CloneName_other\"], ret_valid[\"CloneName_caller\"]))\n",
    "print(adjusted_rand_score(ret_valid[\"CloneName_other\"], ret_valid[\"CloneName_caller\"]))\n",
    "print(adjusted_mutual_info_score(ret_valid[\"CloneName_other\"], ret_valid[\"CloneName_caller\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4301579869830684\n",
      "0.08168476438575224\n",
      "0.20509209020698457\n",
      "0.2556710775047259\n"
     ]
    }
   ],
   "source": [
    "# B-SCITE:\n",
    "pred_path = os.path.join(data_path, \"B-SCITE\")\n",
    "clustering_prediction_file = os.path.join(pred_path, \"results.txt\")\n",
    "predicted = pd.read_table(clustering_prediction_file, sep=\" \")\n",
    "\n",
    "tbl_join = predicted.join(gt, lsuffix='_caller', rsuffix='_other')\n",
    "ret = tbl_join[tbl_join[\"CloneName_other\"].isnull() == False]\n",
    "ret_valid = tbl_join[tbl_join[\"CloneName_other\"].isin(valid_clone_names)]\n",
    "\n",
    "# Read the ancestral matrix line-by-line.\n",
    "with open(os.path.join(pred_path, \"bscite.matrices\"), \"r\") as f:\n",
    "    line = f.readline()\n",
    "    mutation_count = int(line.split()[1])\n",
    "    f.readline()\n",
    "    A = []\n",
    "    for _ in range(mutation_count):\n",
    "        line = f.readline()\n",
    "        A.append(line.split())\n",
    "\n",
    "A = np.asarray(A, dtype=int)\n",
    "A = A[valid_idx]\n",
    "\n",
    "print(v_measure_score(ret_valid[\"CloneName_other\"], ret_valid[\"CloneName_caller\"]))\n",
    "print(adjusted_rand_score(ret_valid[\"CloneName_other\"], ret_valid[\"CloneName_caller\"]))\n",
    "print(adjusted_mutual_info_score(ret_valid[\"CloneName_other\"], ret_valid[\"CloneName_caller\"]))\n",
    "print(np.mean(np.abs(A - A0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.447844219827592\n",
      "0.2823002055523911\n",
      "0.26238513702386707\n",
      "0.19092627599243855\n"
     ]
    }
   ],
   "source": [
    "# Compute the metrics on Canopy.\n",
    "clustering_file = os.path.join(data_path, \"canopy\", \"predicted.csv\")\n",
    "ancestral_matrix_file = os.path.join(data_path, \"canopy\", \"ancestral_matrix.csv\")\n",
    "\n",
    "predicted = pd.read_csv(clustering_file)\n",
    "predicted.columns=[\"ID\", \"CloneName\"]\n",
    "\n",
    "tbl_join = predicted.join(gt, lsuffix='_caller', rsuffix='_other')\n",
    "ret = tbl_join[tbl_join[\"CloneName_other\"].isnull() == False]\n",
    "ret_valid = tbl_join[tbl_join[\"CloneName_other\"].isin(valid_clone_names)]\n",
    "\n",
    "ancestral_matrix = np.asarray(pd.read_table(ancestral_matrix_file, header=None, sep=\" \"))\n",
    "ancestral_matrix = ancestral_matrix[valid_idx]\n",
    "\n",
    "print(v_measure_score(ret_valid[\"CloneName_other\"], ret_valid[\"CloneName_caller\"]))\n",
    "print(adjusted_rand_score(ret_valid[\"CloneName_other\"], ret_valid[\"CloneName_caller\"]))\n",
    "print(adjusted_mutual_info_score(ret_valid[\"CloneName_other\"], ret_valid[\"CloneName_caller\"]))\n",
    "print(np.mean(np.abs(ancestral_matrix - A0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.60577903472376e-16\n",
      "0.0\n",
      "2.6057790347237605e-16\n",
      "0.2684310018903592\n"
     ]
    }
   ],
   "source": [
    "# PhyloWGS:\n",
    "clustering_file = os.path.join(data_path, \"phylowgs\", \"clustering.txt\")\n",
    "ancestral_matrix_file = os.path.join(data_path, \"phylowgs\", \"ancestral_matrix.txt\")\n",
    "\n",
    "predicted = pd.read_table(clustering_file, header=None, names=[\"ID\", \"CloneName\"], sep=\" \")\n",
    "ancestral_matrix = np.asarray(pd.read_table(ancestral_matrix_file, header=None, sep=\" \"))\n",
    "\n",
    "tbl_join = predicted.join(gt, lsuffix='_caller', rsuffix='_other')\n",
    "ret = tbl_join[tbl_join[\"CloneName_other\"].isnull() == False]\n",
    "ret_valid = tbl_join[tbl_join[\"CloneName_other\"].isin(valid_clone_names)]\n",
    "\n",
    "print(v_measure_score(ret_valid[\"CloneName_other\"], ret_valid[\"CloneName_caller\"]))\n",
    "print(adjusted_rand_score(ret_valid[\"CloneName_other\"], ret_valid[\"CloneName_caller\"]))\n",
    "print(adjusted_mutual_info_score(ret_valid[\"CloneName_other\"], ret_valid[\"CloneName_caller\"]))\n",
    "print(np.mean(np.abs(A0 - ancestral_matrix[valid_idx])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, we will do comparison on 10X data\n",
    "- PhylEx\n",
    "- TSSB\n",
    "- Canopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/Users/seonghwanjun/PhylExAnalysis/_output/HGSOC_10X/\"\n",
    "\n",
    "gt = pd.read_csv(\"/Users/seonghwanjun/PhylExAnalysis/data/HGSOC_10X_gt.txt\", header=0, sep=\" \")\n",
    "valid_clone_names = [\"A_B_C_D_E_F_G_H_I\", \"A_B_C_D\", \"A_B\", \"C_D\", \"A\", \"B\", \"C\", \"D\", \"E_F_G_H_I\", \"E_F\", \"E\", \"F\"]\n",
    "\n",
    "# Evaluate the ancestral metric.\n",
    "# Get the true ancestral metric: not many SNVs, just do a plain double for loops. \n",
    "snv_count = gt.shape[0]\n",
    "A = np.zeros(shape = (snv_count, snv_count))\n",
    "for i in range(snv_count):\n",
    "    clone_i = set(gt.iloc[i][\"CloneName\"].split(\"_\"))\n",
    "    for j in range(snv_count):\n",
    "        clone_j = set(gt.iloc[j][\"CloneName\"].split(\"_\"))\n",
    "        if clone_i != clone_j and clone_j.issubset(clone_i):\n",
    "            A[i,j] = 1\n",
    "\n",
    "idx = np.array(np.where(gt[\"CloneName\"].isin(valid_clone_names)))[0]\n",
    "valid_idx = np.ix_(idx, idx)\n",
    "A0 = A[valid_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.35924743 0.20642445 0.26550135 0.23321762]\n",
      "[0.04175973 0.03233021 0.03756476 0.01285182]\n",
      "[[0.3452676  0.19168738 0.25093872 0.23646102]\n",
      " [0.32491389 0.20821186 0.25210552 0.22634398]\n",
      " [0.36825671 0.21408401 0.26479319 0.22416187]\n",
      " [0.29516966 0.18575727 0.20430549 0.24042849]\n",
      " [0.37108071 0.19501037 0.28034681 0.22812934]\n",
      " [0.34770504 0.17285554 0.26361354 0.2388415 ]\n",
      " [0.35978674 0.19345951 0.25519235 0.24042849]\n",
      " [0.41007804 0.21194732 0.30368761 0.22912121]\n",
      " [0.26746092 0.14573752 0.17549935 0.26304305]\n",
      " [0.31072338 0.15471751 0.23509679 0.25609998]\n",
      " [0.37312503 0.22830871 0.27131184 0.22832771]\n",
      " [0.39147698 0.21611203 0.28906949 0.24320571]\n",
      " [0.3584095  0.22231637 0.2654479  0.23090657]\n",
      " [0.32185852 0.21407826 0.22319856 0.23606427]\n",
      " [0.36133818 0.16616436 0.26669551 0.24439595]\n",
      " [0.41767983 0.21659528 0.32312607 0.22733585]\n",
      " [0.37850337 0.23514835 0.28956632 0.22475699]\n",
      " [0.41098739 0.29310614 0.30836245 0.20273755]\n",
      " [0.3345835  0.22231549 0.25170688 0.21920254]\n",
      " [0.43654356 0.24087576 0.33596257 0.22436025]]\n"
     ]
    }
   ],
   "source": [
    "# Our method\n",
    "rep_count = 20\n",
    "metrics = np.zeros([rep_count, 4])\n",
    "for rep in range(rep_count):\n",
    "    rep_path = \"/Users/seonghwanjun/PhylExAnalysis/_output/HGSOC_10X/phylex/chain\" + str(rep)\n",
    "    predicted = pd.read_csv(rep_path + \"/joint/tree0/cluster_labels.tsv\", header=None, sep=\"\\t\", names=[\"ID\", \"CloneName\"])\n",
    "    tbl_join = predicted.join(gt, lsuffix='_caller', rsuffix='_other')\n",
    "    ret = tbl_join[tbl_join[\"CloneName_other\"].isnull() == False]\n",
    "    ret_valid = tbl_join[tbl_join[\"CloneName_other\"].isin(valid_clone_names)]\n",
    "\n",
    "    ancestral_matrix = pd.read_csv(rep_path + \"/joint/tree0/ancestral_matrix.csv\", header=None)\n",
    "    ancestral_matrix = np.asarray(ancestral_matrix)\n",
    "    ancestral_matrix_0 = ancestral_matrix[valid_idx]\n",
    "    metrics[rep,0] = v_measure_score(ret_valid[\"CloneName_other\"], ret_valid[\"CloneName_caller\"])\n",
    "    metrics[rep,1] = adjusted_rand_score(ret_valid[\"CloneName_other\"], ret_valid[\"CloneName_caller\"])\n",
    "    metrics[rep,2] = adjusted_mutual_info_score(ret_valid[\"CloneName_other\"], ret_valid[\"CloneName_caller\"])\n",
    "    metrics[rep,3] = np.mean(np.abs(ancestral_matrix_0 - A0))\n",
    "    \n",
    "# V-measure, adjusted rand score, adjusted mutual info, ancestral metric.\n",
    "print(metrics.mean(0))\n",
    "print(metrics.std(0))\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2031598  0.15447029 0.1564563  0.23805793]\n",
      "[0.04313064 0.04902003 0.04950668 0.02520797]\n",
      "[[0.23302675 0.16781757 0.18234865 0.23963499]\n",
      " [0.17750419 0.10614669 0.12068581 0.24796667]\n",
      " [0.13716754 0.05611451 0.06413609 0.30470145]\n",
      " [0.26290119 0.22004112 0.22848329 0.20710177]\n",
      " [0.17091626 0.15671862 0.13245661 0.23209681]\n",
      " [0.15077375 0.10912486 0.09018903 0.2685975 ]\n",
      " [0.18207864 0.1107243  0.1281407  0.26046419]\n",
      " [0.19414306 0.14720837 0.14037971 0.25709185]\n",
      " [0.20755505 0.15229581 0.17162796 0.2269391 ]\n",
      " [0.27839628 0.25187088 0.24430484 0.20075382]\n",
      " [0.25879597 0.22400507 0.20982058 0.20511803]\n",
      " [0.2150326  0.16893296 0.1791509  0.22297163]\n",
      " [0.26072911 0.20274493 0.21188146 0.2209879 ]\n",
      " [0.124174   0.10814338 0.08383262 0.25431462]\n",
      " [0.22559928 0.18185054 0.18992964 0.21821067]\n",
      " [0.14955087 0.08376118 0.09396274 0.26502678]\n",
      " [0.20755505 0.15229581 0.17162796 0.2269391 ]\n",
      " [0.22559928 0.18185054 0.18992964 0.21821067]\n",
      " [0.22366269 0.1857212  0.17217865 0.22931958]\n",
      " [0.17803435 0.1220375  0.12405911 0.25471137]]\n"
     ]
    }
   ],
   "source": [
    "# TSSB\n",
    "rep_count = 20\n",
    "metrics = np.zeros([rep_count, 4])\n",
    "for rep in range(rep_count):\n",
    "    rep_path = \"/Users/seonghwanjun/PhylExAnalysis/_output/HGSOC_10X/tssb/chain\" + str(rep)\n",
    "    predicted = pd.read_csv(rep_path + \"/joint/tree0/cluster_labels.tsv\", header=None, sep=\"\\t\", names=[\"ID\", \"CloneName\"])\n",
    "    tbl_join = predicted.join(gt, lsuffix='_caller', rsuffix='_other')\n",
    "    ret = tbl_join[tbl_join[\"CloneName_other\"].isnull() == False]\n",
    "    ret_valid = tbl_join[tbl_join[\"CloneName_other\"].isin(valid_clone_names)]\n",
    "\n",
    "    ancestral_matrix = pd.read_csv(rep_path + \"/joint/tree0/ancestral_matrix.csv\", header=None)\n",
    "    ancestral_matrix = np.asarray(ancestral_matrix)\n",
    "    ancestral_matrix_0 = ancestral_matrix[valid_idx]\n",
    "    metrics[rep,0] = v_measure_score(ret_valid[\"CloneName_other\"], ret_valid[\"CloneName_caller\"])\n",
    "    metrics[rep,1] = adjusted_rand_score(ret_valid[\"CloneName_other\"], ret_valid[\"CloneName_caller\"])\n",
    "    metrics[rep,2] = adjusted_mutual_info_score(ret_valid[\"CloneName_other\"], ret_valid[\"CloneName_caller\"])\n",
    "    metrics[rep,3] = np.mean(np.abs(ancestral_matrix_0 - A0))\n",
    "    \n",
    "# V-measure, adjusted rand score, adjusted mutual info, ancestral metric.\n",
    "print(metrics.mean(0))\n",
    "print(metrics.std(0))\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30457639884702015\n",
      "0.17605997183999517\n",
      "0.1684235272613015\n",
      "0.24479269986113866\n"
     ]
    }
   ],
   "source": [
    "# Compute the metrics on Canopy.\n",
    "clustering_file = os.path.join(data_path, \"canopy\", \"predicted.csv\")\n",
    "ancestral_matrix_file = os.path.join(data_path, \"canopy\", \"ancestral_matrix.csv\")\n",
    "\n",
    "predicted = pd.read_csv(clustering_file)\n",
    "predicted.columns=[\"ID\", \"CloneName\"]\n",
    "\n",
    "tbl_join = predicted.join(gt, lsuffix='_caller', rsuffix='_other')\n",
    "ret = tbl_join[tbl_join[\"CloneName_other\"].isnull() == False]\n",
    "ret_valid = tbl_join[tbl_join[\"CloneName_other\"].isin(valid_clone_names)]\n",
    "\n",
    "ancestral_matrix = np.asarray(pd.read_table(ancestral_matrix_file, header=None, sep=\" \"))\n",
    "ancestral_matrix = ancestral_matrix[valid_idx]\n",
    "\n",
    "print(v_measure_score(ret_valid[\"CloneName_other\"], ret_valid[\"CloneName_caller\"]))\n",
    "print(adjusted_rand_score(ret_valid[\"CloneName_other\"], ret_valid[\"CloneName_caller\"]))\n",
    "print(adjusted_mutual_info_score(ret_valid[\"CloneName_other\"], ret_valid[\"CloneName_caller\"]))\n",
    "print(np.mean(np.abs(ancestral_matrix - A0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
